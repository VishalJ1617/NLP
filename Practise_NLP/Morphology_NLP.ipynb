{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff250276",
   "metadata": {},
   "source": [
    "Date : 10/12/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbe3b3",
   "metadata": {},
   "source": [
    "## Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8fe4d1",
   "metadata": {},
   "source": [
    "<img src=\"Nov_blog_header_Morphology.png\" alt=\"intro\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc272873",
   "metadata": {},
   "source": [
    "1. Morphology refers to the process of stripping the word to basic unit of meaning.\n",
    "2. The basic unit of word is known as **morphemes**\n",
    "3. Types of morphemes are 1) **Free morphemes**, 2) **Bound morphemes**\n",
    "4. **Free morphemes** = free morphemes are the one which form a word on thier own.\n",
    "6. **Bound morpheme** = multiple morphemes come togther to form a word are known as Bound morphemes\n",
    "5. Libraries that facilitate morphology analysis are polyglot, morfessor, pyICU and pycld2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5059839",
   "metadata": {},
   "source": [
    "<img src='1200px-Major_levels_of_linguistic_structure.svg.png' alt=\"co_circle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917d332",
   "metadata": {},
   "source": [
    "# Code - Morhphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1ad36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------\n",
    "### Imporing libraries\n",
    "### ------------------\n",
    "\n",
    "from polyglot.text import Word, Text\n",
    "\n",
    "import regex as re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6057d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------\n",
    "### Input text data\n",
    "### ------------------\n",
    "\n",
    "text = 'I went to the store, but they were closed, so I had to go to another store.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9f8348",
   "metadata": {},
   "source": [
    "## Process Flow\n",
    "\n",
    "1. Clean input text data\n",
    "2. Convert the clean dataset into word token\n",
    "3. Remove punctuations from clean tokens dataset\n",
    "4. Apply mophological analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c04550",
   "metadata": {},
   "source": [
    "### 1. Convert the text dataset into word token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e29a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'store',\n",
       " ',',\n",
       " 'but',\n",
       " 'they',\n",
       " 'were',\n",
       " 'closed',\n",
       " ',',\n",
       " 'so',\n",
       " 'I',\n",
       " 'had',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'another',\n",
       " 'store',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization is performed using nltk library (word_tokenize)\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadaa8c",
   "metadata": {},
   "source": [
    "**The elements of the \"text\" has been tokenized, as can be seen above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5346c",
   "metadata": {},
   "source": [
    "### 3. Remove punctuations from clean tokens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9626cf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'store',\n",
       " 'but',\n",
       " 'they',\n",
       " 'were',\n",
       " 'closed',\n",
       " 'so',\n",
       " 'I',\n",
       " 'had',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'another',\n",
       " 'store']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "To remove the punctuations form the tokens list, \n",
    "\n",
    "we will iterate over the list and remove elements which match with elements in the punctuation string\n",
    "'''\n",
    "\n",
    "punc = string.punctuation  # String of all punctuations\n",
    "\n",
    "punc = punc + \"''``\"  # adding elements that were not a part of punctuation, but were in text data\n",
    "\n",
    "clean_text = [word for word in word_tokens if word not in punc]\n",
    "\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62105509",
   "metadata": {},
   "source": [
    "**Data has been cleaned of any punctuations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00674eea",
   "metadata": {},
   "source": [
    "### 4. Apply mophological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d53e53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ----> ['I']\n",
      "went ----> ['went']\n",
      "to ----> ['to']\n",
      "the ----> ['the']\n",
      "store ----> ['store']\n",
      "but ----> ['but']\n",
      "they ----> ['the', 'y']\n",
      "were ----> ['were']\n",
      "closed ----> ['close', 'd']\n",
      "so ----> ['s', 'o']\n",
      "I ----> ['I']\n",
      "had ----> ['had']\n",
      "to ----> ['to']\n",
      "go ----> ['go']\n",
      "to ----> ['to']\n",
      "another ----> ['an', 'other']\n",
      "store ----> ['store']\n"
     ]
    }
   ],
   "source": [
    "# Now we will apply morphological analysis to clean word tokens dataset\n",
    "\n",
    "# To apply morphlogical analysis, we will iterate over the list of words and apply 'Word' method to each\n",
    "\n",
    "for element in clean_text:\n",
    "    \n",
    "    element = Word(element, language = 'en')\n",
    "    \n",
    "    print(element, '---->', element.morphemes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
